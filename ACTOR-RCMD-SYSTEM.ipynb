{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52W0Qbm_NbkO"
      },
      "source": [
        "## TASK 1:\n",
        "# Import Necessary Libraries\n",
        "This cell installs and imports the necessary libraries for the tasks. These include:\n",
        "\n",
        "requests for making API calls.\n",
        "beautifulsoup4 for parsing HTML content during web scraping.\n",
        "pandas for handling and manipulating datasets.\n",
        "time for adding delays in requests to avoid overloading APIs or web servers.\n",
        "tqdm for creating progress bars to monitor the progress of tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qj8IzHm5Yqn",
        "outputId": "44b8aba8-4ccf-420f-dfc2-76666f6f0d19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "!pip install requests beautifulsoup4\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPeTCmEyN47S"
      },
      "source": [
        "# Load the Movies Dataset\n",
        "This cell loads the dataset containing information about movies. The dataset is expected to be in a CSV file named movies_set1.csv. The cell also displays the first few rows of the dataset using head() to ensure it has been loaded correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ui0VsI1S9MNG",
        "outputId": "2252184d-0e4d-4ae1-ab3d-fe6662bf1dde"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"movies_df\",\n  \"rows\": 20000,\n  \"fields\": [\n    {\n      \"column\": \"movieId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 78636,\n        \"min\": 25,\n        \"max\": 292757,\n        \"num_unique_values\": 20000,\n        \"samples\": [\n          2532,\n          138338,\n          200426\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19987,\n        \"samples\": [\n          \"She Ball (2020)\",\n          \"time for sushi (2017)\",\n          \"The Model and the Marriage Broker (1951)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"genres\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 932,\n        \"samples\": [\n          \"Comedy|Crime|Drama|Horror\",\n          \"Adventure|Drama|Thriller\",\n          \"Adventure|War|Western\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "movies_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-aa8c29f6-798b-49dd-b8ce-469b1e402b02\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>120510</td>\n",
              "      <td>Value for Money (1955)</td>\n",
              "      <td>Comedy|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>212955</td>\n",
              "      <td>Face of Evil (1996)</td>\n",
              "      <td>Drama|Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>193912</td>\n",
              "      <td>Spring 1941 (2007)</td>\n",
              "      <td>Drama|Romance|War</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>163921</td>\n",
              "      <td>Wolf Creek (2016)</td>\n",
              "      <td>Crime|Horror|Thriller</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>126652</td>\n",
              "      <td>Raven the Little Rascal (2012)</td>\n",
              "      <td>Animation|Children</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa8c29f6-798b-49dd-b8ce-469b1e402b02')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aa8c29f6-798b-49dd-b8ce-469b1e402b02 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aa8c29f6-798b-49dd-b8ce-469b1e402b02');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4f8053c0-5c5e-4fa4-ab66-2fc3afa5c06f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4f8053c0-5c5e-4fa4-ab66-2fc3afa5c06f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4f8053c0-5c5e-4fa4-ab66-2fc3afa5c06f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   movieId                           title                 genres\n",
              "0   120510          Value for Money (1955)         Comedy|Romance\n",
              "1   212955             Face of Evil (1996)         Drama|Thriller\n",
              "2   193912              Spring 1941 (2007)      Drama|Romance|War\n",
              "3   163921               Wolf Creek (2016)  Crime|Horror|Thriller\n",
              "4   126652  Raven the Little Rascal (2012)     Animation|Children"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the movies dataset\n",
        "movies_path = 'movies_set1.csv'  # Adjust path accordingly\n",
        "movies_df = pd.read_csv(movies_path)\n",
        "movies_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRecee3KOCVX"
      },
      "source": [
        "# Set TMDb API Key\n",
        "This cell defines the API key required for making requests to The Movie Database (TMDb) API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AO1-Nxj_A6q-"
      },
      "outputs": [],
      "source": [
        "# TMDb API key\n",
        "API_KEY = '4aad8158e12f512a80a29ee5540098dc'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpvaAMxtOT7y"
      },
      "source": [
        "# Define Base URLs for TMDb API\n",
        "\n",
        "This cell sets up the base URLs for making requests to The Movie Database (TMDb) API. The search_url is used for searching movies by title, and credits_url_template is used to retrieve the cast (actors) for a given movie by its ID."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZuSqonqBFfA"
      },
      "outputs": [],
      "source": [
        "# Base URLs for TMDb API\n",
        "search_url = 'https://api.themoviedb.org/3/search/movie'\n",
        "credits_url_template = 'https://api.themoviedb.org/3/movie/{movie_id}/credits'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-Cp1LNn9iI-"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Prepare a dictionary to store movie-actor relationships\n",
        "movie_actor_dict = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISwPKMAZOdDO"
      },
      "source": [
        "# Fetching Top Actors for Movies Using TMDb API\n",
        "In this step, we fetch the top 5 actors for each movie in the dataset by querying the TMDb API. This helps link movies to their actors, which is essential for creating the user-actor rating matrix later on.\n",
        "\n",
        "The get_top_actors function searches for the movie by title, retrieves its ID, and then fetches the cast details. It extracts the top 5 actors from the cast and returns them. If any errors occur during this process, such as network issues, an empty list is returned for that movie.\n",
        "\n",
        "To speed up the process, we use ThreadPoolExecutor to make parallel API requests. This allows us to fetch actor details for multiple movies simultaneously. The results are stored in a dictionary with movie titles as keys and actor lists as values. We also use tqdm to show the progress of the task, providing real-time feedback on the number of completed requests.\n",
        "\n",
        "This approach optimizes the process of fetching actor data, making it faster and more efficient for large datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltbW3XeIEX1X"
      },
      "outputs": [],
      "source": [
        "# from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "# # Function to get movie ID and then retrieve top actors\n",
        "# def get_top_actors(movie_title):\n",
        "#     try:\n",
        "#         # Search for the movie by title\n",
        "#         search_params = {'api_key': API_KEY, 'query': movie_title}\n",
        "#         search_response = requests.get(search_url, params=search_params).json()\n",
        "\n",
        "#         if search_response['results']:\n",
        "#             movie_id = search_response['results'][0]['id']  # Get the first matching movie ID\n",
        "\n",
        "#             # Get the credits (cast) for the movie\n",
        "#             credits_url = credits_url_template.format(movie_id=movie_id)\n",
        "#             credits_params = {'api_key': API_KEY}\n",
        "#             credits_response = requests.get(credits_url, params=credits_params).json()\n",
        "\n",
        "#             # Extract the top 5 actors\n",
        "#             actors = [cast['name'] for cast in credits_response.get('cast', [])[:5]]\n",
        "#             return movie_title, actors\n",
        "#         else:\n",
        "#             return movie_title, []\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error fetching actors for {movie_title}: {e}\")\n",
        "#         return movie_title, []\n",
        "\n",
        "# # Use ThreadPoolExecutor to parallelize API requests\n",
        "# with ThreadPoolExecutor(max_workers=10) as executor:\n",
        "#     future_to_movie = {executor.submit(get_top_actors, row['title']): row['title'] for _, row in movies_df.iterrows()}\n",
        "#     for future in tqdm(as_completed(future_to_movie), total=len(future_to_movie)):\n",
        "#         movie_title, actors = future.result()\n",
        "#         movie_actor_dict[movie_title] = actors\n",
        "\n",
        "import pandas as pd\n",
        "import requests\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import time\n",
        "\n",
        "# Load MovieLens movies (must contain movieId and title)\n",
        "movies_df = pd.read_csv(\"movies_set1.csv\")   # e.g., user-movie mappings\n",
        "\n",
        "API_KEY = \"YOUR_TMDB_API_KEY\"   # Insert your TMDb key\n",
        "search_url = \"https://api.themoviedb.org/3/search/movie\"\n",
        "credits_url = \"https://api.themoviedb.org/3/movie/{movie_id}/credits\"\n",
        "\n",
        "def get_top_actors(movie_title):\n",
        "    \"\"\"\n",
        "    Search TMDb movie_id for the title, then fetch top 5 actors.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = requests.get(search_url, params={\"api_key\": API_KEY, \"query\": movie_title})\n",
        "        data = response.json()\n",
        "\n",
        "        if not data[\"results\"]:\n",
        "            return None, None\n",
        "\n",
        "        movie_id = data[\"results\"][0][\"id\"]\n",
        "\n",
        "        # Fetch credits\n",
        "        credits_response = requests.get(\n",
        "            credits_url.format(movie_id=movie_id),\n",
        "            params={\"api_key\": API_KEY}\n",
        "        ).json()\n",
        "\n",
        "        cast = credits_response.get(\"cast\", [])\n",
        "        top_actors = [actor[\"name\"] for actor in cast[:5]]\n",
        "\n",
        "        return movie_id, top_actors\n",
        "\n",
        "    except Exception:\n",
        "        return None, None\n",
        "\n",
        "\n",
        "movie_actor_list = []\n",
        "\n",
        "def process_row(row):\n",
        "    title = row[\"title\"]\n",
        "    movieId = row[\"movieId\"]\n",
        "\n",
        "    movie_id_db, actors_list = get_top_actors(title)\n",
        "\n",
        "    # Skip missing\n",
        "    if movie_id_db is None or actors_list is None:\n",
        "        return\n",
        "\n",
        "    movie_actor_list.append({\n",
        "        \"movieId\": movieId,          # MovieLens ID\n",
        "        \"movie_title\": title,\n",
        "        \"movie_id_db\": movie_id_db,  # TMDb ID\n",
        "        \"actor_list\": actors_list    # List of 5 actors\n",
        "    })\n",
        "\n",
        "\n",
        "# Run scraping in parallel\n",
        "with ThreadPoolExecutor(max_workers=10) as executor:\n",
        "    executor.map(process_row, movies_df.to_dict(\"records\"))\n",
        "\n",
        "# Convert to DataFrame\n",
        "movie_actors_df = pd.DataFrame(movie_actor_list)\n",
        "\n",
        "# Save\n",
        "movie_actors_df.to_csv(\"movie_actors.csv\", index=False)\n",
        "print(\"movie_actors.csv created successfully!\")\n",
        "movie_actors_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0EnNe_GOx1z"
      },
      "source": [
        "# Saving Movie and Actor Data to CSV\n",
        "After retrieving the top 5 actors for each movie, the next step is to organize and save the results for further use. This cell creates a new DataFrame from the movie_actor_dict dictionary, where each movie title is paired with a list of top actors. The DataFrame is then exported as a CSV file (movie_actors.csv), making it easy to access and work with the movie-actor associations in future tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlHNLXne-H0V",
        "outputId": "656334de-b2ec-4da0-a0fb-2cf3705ea22c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top actors data saved successfully.\n"
          ]
        }
      ],
      "source": [
        "# # Save the results to a new DataFrame and export it as a CSV\n",
        "# movie_actors_df = pd.DataFrame(list(movie_actor_dict.items()), columns=['Movie Title', 'Top Actors'])\n",
        "# movie_actors_df.to_csv('movie_actors.csv', index=False)  # Adjust path accordingly\n",
        "\n",
        "# print(\"Top actors data saved successfully.\")\n",
        "\n",
        "\n",
        "# STEP 2 — Convert actor list to one actor per row\n",
        "\n",
        "# This will create movie_actor_relationships.csv having:\n",
        "\n",
        "# | movieId | movie_title | movie_id_db | actor_name |\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the scraped file\n",
        "df = pd.read_csv(\"movie_actors.csv\")\n",
        "\n",
        "# Convert string list → actual Python list\n",
        "df[\"actor_list\"] = df[\"actor_list\"].apply(eval)\n",
        "\n",
        "# Expand list into multiple rows\n",
        "exploded_df = df.explode(\"actor_list\")\n",
        "\n",
        "# Rename for clarity\n",
        "exploded_df = exploded_df.rename(columns={\n",
        "    \"actor_list\": \"actor_name\"\n",
        "})\n",
        "\n",
        "# Save final relationships file\n",
        "exploded_df.to_csv(\"movie_actor_relationships.csv\", index=False)\n",
        "\n",
        "print(\"movie_actor_relationships.csv created successfully!\")\n",
        "exploded_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FezTCqWWHnlV"
      },
      "source": [
        "# TASK 2\n",
        "# Constructing the User-Actor Rating Matrix\n",
        "This cell outlines the process of constructing the user-actor rating matrix from the user-movie ratings and movie-actor associations. The steps are as follows:\n",
        "\n",
        "Loading Datasets: The user-movie ratings (ratings_set1.csv) and movie-actor associations (movie_actors.csv) are loaded into Pandas DataFrames.\n",
        "\n",
        "Data Preparation: The movie IDs in both datasets are converted to strings to ensure they match properly during the merge process.\n",
        "\n",
        "Exploding the Actor List: The top_actors column, which contains comma-separated actor names, is converted into a list. Then, the list is \"exploded\" so that each actor appears on a separate row for the corresponding movie.\n",
        "\n",
        "Merging Data: The ratings data is merged with the expanded movie-actor data to associate each user's rating with the corresponding actors of the movies they have rated.\n",
        "\n",
        "Calculating Average Ratings: For each user-actor pair, the average rating is computed, which represents how much a user likes an actor based on the movies they have rated.\n",
        "\n",
        "Creating the User-Actor Rating Matrix: The long-format data is converted into a pivot table (user-actor rating matrix), which is useful for recommendation algorithms.\n",
        "\n",
        "Saving Results: The user-actor ratings and matrix are saved as CSV files (user_actor_ratings.csv and user_actor_matrix.csv) for further use in model training and evaluation.\n",
        "\n",
        "The resulting DataFrame provides the necessary structure for applying recommendation algorithms and generating personalized actor recommendations for users based on their preferences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kr7cdUz1OWBV",
        "outputId": "7b9a41d6-8606-497b-e1c1-b303db8df57c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scikit-surprise\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/154.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.13.1)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp310-cp310-linux_x86_64.whl size=2357278 sha256=6b19d0e5afdf8d1a55cc75180e92b1abe8e82e0b7410c95953f31fd33b161a88\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/3f/df/6acbf0a40397d9bf3ff97f582cc22fb9ce66adde75bc71fd54\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.4\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-surprise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lk3hKIr2H58B",
        "outputId": "9349360c-aa49-4c8c-8029-91b56b4a6d4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ratings Columns: Index(['userId', 'movieId', 'rating', 'timestamp'], dtype='object')\n",
            "Movie Actors Columns: Index(['movie_id_db', 'movie_title', 'actor_name'], dtype='object')\n",
            "Updated Ratings Columns: Index(['userId', 'movieId', 'rating', 'timestamp'], dtype='object')\n",
            "Updated Movie Actors Columns: Index(['movie_id_db', 'movie_title', 'actor_name'], dtype='object')\n",
            "User-Actor rating dataset has been saved as 'user_actor_ratings.csv'.\n",
            "   userId           actor_name  average_rating\n",
            "0       5        Aaron Izbicki             4.0\n",
            "1       5  Aaron Michael Lacey             4.0\n",
            "2       5        Afemo Omilami             4.0\n",
            "3       5  Afram Bill Williams             4.0\n",
            "4       5        Al Harrington             4.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the datasets\n",
        "ratings = pd.read_csv('/content/ratings_set1.csv')  # User-movie ratings\n",
        "movie_actors = pd.read_csv('/content/movie_actor_relationships.csv')  # Movie-actor associations\n",
        "\n",
        "# Print the columns to check for discrepancies in column names\n",
        "print(\"Ratings Columns:\", ratings.columns)\n",
        "print(\"Movie Actors Columns:\", movie_actors.columns)\n",
        "\n",
        "# Strip any extra spaces in column names\n",
        "ratings.columns = ratings.columns.str.strip()\n",
        "movie_actors.columns = movie_actors.columns.str.strip()\n",
        "\n",
        "# Check again for correct column names\n",
        "print(\"Updated Ratings Columns:\", ratings.columns)\n",
        "print(\"Updated Movie Actors Columns:\", movie_actors.columns)\n",
        "\n",
        "# Ensure 'movieId' column is in the ratings dataset and 'movie_id_db' is in the movie_actors dataset\n",
        "if 'movieId' not in ratings.columns:\n",
        "    raise ValueError(\"Column 'movieId' not found in the ratings dataset\")\n",
        "if 'movie_id_db' not in movie_actors.columns:\n",
        "    raise ValueError(\"Column 'movie_id_db' not found in the movie_actors dataset\")\n",
        "\n",
        "# Merge ratings with movie_actors on movieId (ratings dataset) and movie_id_db (movie_actors dataset)\n",
        "user_movie_actors = pd.merge(ratings, movie_actors[['movie_id', 'actor_name']],\n",
        "                             left_on='movieId', right_on='movie_id', how='inner')\n",
        "\n",
        "# Group by userId and actor_name, and calculate the average rating per actor\n",
        "user_actor_ratings = (\n",
        "    user_movie_actors.groupby(['userId', 'actor_name'])['rating']\n",
        "    .mean()\n",
        "    .reset_index()\n",
        "    .rename(columns={'rating': 'average_rating'})\n",
        ")\n",
        "\n",
        "# Optional: Preprocessing to remove low-activity users and actors\n",
        "# Filter out actors with very few ratings\n",
        "min_ratings_per_actor = 5\n",
        "actor_rating_counts = user_actor_ratings['actor_name'].value_counts()\n",
        "active_actors = actor_rating_counts[actor_rating_counts >= min_ratings_per_actor].index\n",
        "user_actor_ratings = user_actor_ratings[user_actor_ratings['actor_name'].isin(active_actors)]\n",
        "\n",
        "# Filter out users with very few ratings\n",
        "min_ratings_per_user = 5\n",
        "user_rating_counts = user_actor_ratings['userId'].value_counts()\n",
        "active_users = user_rating_counts[user_rating_counts >= min_ratings_per_user].index\n",
        "user_actor_ratings = user_actor_ratings[user_actor_ratings['userId'].isin(active_users)]\n",
        "\n",
        "# Save the user-actor rating dataset to a CSV file\n",
        "user_actor_ratings.to_csv('/content/user_actor_ratings.csv', index=False)\n",
        "\n",
        "# Print a success message and display the first few rows of the saved dataset\n",
        "print(\"User-Actor rating dataset has been saved as 'user_actor_ratings.csv'.\")\n",
        "print(user_actor_ratings.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9p58jNzpGZy",
        "outputId": "50861f74-f4d8-46e5-d46a-50e75b680d45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['movie_id_db', 'movie_title', 'actor_name'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(movie_actors.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xd28JD5PW0N"
      },
      "source": [
        "# TASK 3\n",
        "# Model Training and Evaluation with SVD\n",
        "This cell implements the training and evaluation of the Singular Value Decomposition (SVD) algorithm using the Surprise library. The steps are outlined as follows:\n",
        "\n",
        "Loading the Data: The user-actor rating data (user_actor_ratings.csv) is loaded into a Pandas DataFrame. This data contains ratings of actors by different users, and it is essential for building the recommendation model.\n",
        "\n",
        "Setting Up the Surprise Reader: A Reader object is defined with the rating scale. The minimum and maximum values of the avg_actor_rating column are extracted from the data and passed to the Reader. This defines the range of the ratings for the Surprise algorithm.\n",
        "\n",
        "Loading the Data into Surprise Dataset: The Dataset.load_from_df() method is used to convert the user-actor rating DataFrame into a Surprise dataset format. This dataset contains three columns: userId, actorId, and avg_actor_rating.\n",
        "\n",
        "Initializing the SVD Algorithm: The Singular Value Decomposition (SVD) algorithm is initialized using SVD(). SVD is a popular matrix factorization technique used in collaborative filtering for making recommendations.\n",
        "\n",
        "Cross-Validation: The cross_validate() function is used to perform 5-fold cross-validation on the SVD algorithm. This function splits the data into five parts, trains the model on four parts, and evaluates it on the fifth. It calculates two common evaluation metrics: RMSE (Root Mean Squared Error) and MAE (Mean Absolute Error).\n",
        "\n",
        "Results: The evaluation results (RMSE and MAE) are printed out, providing insights into the performance of the model on the user-actor rating data.\n",
        "\n",
        "By performing cross-validation, we can assess the generalization ability of the model and its performance in predicting actor preferences for users."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqwI9rfjKC6N",
        "outputId": "8984a684-a78c-4ec2-833d-f2139c21023c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating RMSE, MAE of algorithm SVD on 3 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
            "RMSE (testset)    0.6677  0.6698  0.6688  0.6688  0.0009  \n",
            "MAE (testset)     0.4669  0.4682  0.4671  0.4674  0.0006  \n",
            "Fit time          54.96   57.55   56.61   56.37   1.07    \n",
            "Test time         19.09   21.83   19.05   19.99   1.30    \n",
            "Cross-Validation Results (RMSE, MAE):\n",
            "{'test_rmse': array([0.66768767, 0.66984269, 0.66878309]), 'test_mae': array([0.46694471, 0.4681875 , 0.46707722]), 'fit_time': (54.96441674232483, 57.548688650131226, 56.610989809036255), 'test_time': (19.094894886016846, 21.830989599227905, 19.05217742919922)}\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from surprise import SVD, Dataset, Reader\n",
        "from surprise.model_selection import cross_validate\n",
        "\n",
        "# Load the user-actor rating data\n",
        "average_rating = pd.read_csv('/content/user_actor_ratings.csv')  # from Task 2\n",
        "\n",
        "# Define a reader for Surprise with the expected rating scale (1-5 for MovieLens)\n",
        "reader = Reader(rating_scale=(average_rating['average_rating'].min(),\n",
        "                              average_rating['average_rating'].max()))\n",
        "\n",
        "# Load the data into Surprise Dataset\n",
        "data = Dataset.load_from_df(average_rating[['userId', 'actor_name', 'average_rating']], reader)\n",
        "\n",
        "# Initialize the SVD algorithm\n",
        "svd_algo = SVD()\n",
        "\n",
        "# Train and evaluate the model using cross-validation (e.g., 3-fold)\n",
        "cross_val_results = cross_validate(svd_algo, data, measures=['RMSE', 'MAE'], cv=3, verbose=True)\n",
        "\n",
        "# Output results\n",
        "print(\"Cross-Validation Results (RMSE, MAE):\")\n",
        "print(cross_val_results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7v5nGMPkPkuk"
      },
      "source": [
        "# TASK 4\n",
        "# Actor Recommendation for Users Using SVD\n",
        "This cell focuses on using the trained Singular Value Decomposition (SVD) model to generate personalized actor recommendations for users. Here's how the code works:\n",
        "\n",
        "Loading Data and Training the Model:\n",
        "\n",
        "The user_actor_ratings.csv dataset is loaded, which contains user ratings for different actors. The dataset is transformed into a format suitable for the Surprise library using the Reader and Dataset classes.\n",
        "The full training set is created using build_full_trainset() and the SVD model is trained with svd_algo.fit().\n",
        "Generating Actor Recommendations:\n",
        "\n",
        "A list of all unique actor IDs is extracted from the user_actor_ratings DataFrame. This will be used to generate predictions for all actors that a given user has not yet rated.\n",
        "The recommend_actors function is designed to recommend top-N actors for a specific user. It takes into account the following:\n",
        "Already Rated Actors: The function filters out the actors the user has already rated, ensuring predictions are only made for unrated actors.\n",
        "Predicted Ratings: For each unrated actor, the model predicts a rating using model.predict(user_id, actor_id).est. These predicted ratings are stored and sorted in descending order to prioritize actors the model believes the user would like most.\n",
        "Example Usage:\n",
        "\n",
        "The function is called with user_id = 1 to generate the top 10 actor recommendations. The predicted ratings for these actors are displayed in descending order.\n",
        "Output:\n",
        "\n",
        "The top-10 recommended actors for the given user (ID = 1) are printed along with their predicted ratings, which represent how much the user is likely to enjoy the actor's work.\n",
        "By using this approach, you can provide personalized recommendations of actors based on users' previous ratings, facilitating a tailored movie experience for each individual."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewwoNo2sPSul",
        "outputId": "d83e983a-30b9-4f91-aa48-d20884cd7077"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 10 actor recommendations for user 1:\n",
            "Mario Brega: Predicted Rating = 4.52\n",
            "Eddie Parker: Predicted Rating = 4.49\n",
            "Teresa Harder: Predicted Rating = 4.49\n",
            "Jimmy Grant: Predicted Rating = 4.48\n",
            "Morgan Lund: Predicted Rating = 4.46\n",
            "Raymond Burr: Predicted Rating = 4.45\n",
            "Joseph Ragno: Predicted Rating = 4.44\n",
            "Gunnel Lindblom: Predicted Rating = 4.44\n",
            "Brian Delate: Predicted Rating = 4.44\n",
            "Carol Reed: Predicted Rating = 4.44\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the user-actor rating data\n",
        "average_rating = pd.read_csv('/content/user_actor_ratings.csv')  # from Task 2\n",
        "\n",
        "# Function to generate top-N actor recommendations for a given user using the trained model\n",
        "def recommend_actors(user_id, model, dataset, n=10):\n",
        "    # Get all unique actors\n",
        "    all_actors = dataset['actor_name'].unique()\n",
        "\n",
        "    # Get the list of actors the user has already rated\n",
        "    user_rated_actors = dataset[dataset['userId'] == user_id]['actor_name'].tolist()\n",
        "\n",
        "    # Filter out actors the user has already rated\n",
        "    actors_to_predict = [actor for actor in all_actors if actor not in user_rated_actors]\n",
        "\n",
        "    # Predict the rating for each actor and store in a list\n",
        "    predictions = []\n",
        "    for actor in actors_to_predict:\n",
        "        pred = model.predict(user_id, actor)\n",
        "        predictions.append((actor, pred.est))\n",
        "\n",
        "    # Sort the predictions by estimated rating in descending order\n",
        "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Return the top-N recommendations\n",
        "    return predictions[:n]\n",
        "\n",
        "# Example usage: Generate recommendations for a specific user\n",
        "user_id_to_recommend = 1  # Replace with a valid user ID\n",
        "top_n_recommendations = recommend_actors(user_id_to_recommend, svd_algo, average_rating, n=10)\n",
        "\n",
        "# Display the top-N recommendations\n",
        "print(f\"Top {len(top_n_recommendations)} actor recommendations for user {user_id_to_recommend}:\")\n",
        "for actor, rating in top_n_recommendations:\n",
        "    print(f\"{actor}: Predicted Rating = {rating:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LK7H27tpQYBt"
      },
      "source": [
        "# TASK 5\n",
        "# Evaluation of Actor Recommendation System using SVD\n",
        "This cell evaluates a recommendation system that suggests top-N actors to a user based on their historical ratings using Singular Value Decomposition (SVD). The evaluation metrics used are Precision@k, Recall@k, and NDCG@k, which are standard measures for evaluating the quality of recommendations in collaborative filtering systems.\n",
        "\n",
        "Details of the Code:\n",
        "Data Loading:\n",
        "\n",
        "The user-actor ratings dataset is loaded, which contains columns: userId, actorId, and avg_actor_rating. These represent ratings given by users to actors.\n",
        "SVD Model Training:\n",
        "\n",
        "An SVD model from the surprise library is used to model user-actor interactions. This model is trained on the complete user-actor ratings dataset using the Reader class from the surprise library to handle the rating scale.\n",
        "Actor Recommendations:\n",
        "\n",
        "The function recommend_actors takes a user_id and uses the trained SVD model to predict ratings for actors that the user has not yet rated. It then returns the top-N recommended actors based on the predicted ratings.\n",
        "Evaluation Metrics:\n",
        "\n",
        "Precision@k: Measures the proportion of recommended actors that are relevant (i.e., the user has already rated them).\n",
        "Recall@k: Measures the proportion of relevant actors that are recommended among the top-N recommendations.\n",
        "NDCG@k: Measures the ranking quality of the top-N recommendations by considering the position of relevant actors (discounted cumulative gain).\n",
        "Evaluation Process:\n",
        "\n",
        "The function evaluate_recommendations calculates Precision@k, Recall@k, and NDCG@k for each user in the dataset.\n",
        "It loops through each user, generates the top-N recommendations using recommend_actors, and then calculates the three evaluation metrics.\n",
        "The final evaluation results are the average scores across all users.\n",
        "Results Display:\n",
        "\n",
        "After evaluating the recommendation system, the precision, recall, and NDCG values at k=10 are printed to provide insights into the quality of the recommendations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "bms9bIDmeKxX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from surprise import Dataset, Reader, accuracy\n",
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "# Load the user-actor rating data (from Task 2)\n",
        "user_actor_ratings = pd.read_csv('/content/user_actor_ratings.csv')\n",
        "\n",
        "# Define a reader for Surprise with the expected rating scale\n",
        "reader = Reader(rating_scale=(user_actor_ratings['average_rating'].min(), user_actor_ratings['average_rating'].max()))\n",
        "\n",
        "# Load the data into Surprise's format\n",
        "data = Dataset.load_from_df(user_actor_ratings[['userId', 'actor_name', 'average_rating']], reader)\n",
        "\n",
        "# Load the train and test sets from the pre-split data\n",
        "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Assuming you have a pre-trained model (svd_algo) from previous steps\n",
        "# If not, use: svd_algo.fit(trainset) to train it\n",
        "# Generate predictions for the test set using the pre-trained model\n",
        "predictions = svd_algo.test(testset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7P2snU6TQZfI",
        "outputId": "dc4922ee-d055-4f6d-9850-1d9d8c789423"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User ID: 5\n",
            "Precision@10: 0.9000\n",
            "Recall@10: 0.3214\n",
            "NDCG@10: 0.9306\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Specify the user ID for evaluation\n",
        "specific_user_id = 5  # Replace with the desired user ID\n",
        "\n",
        "# Filter predictions for the specific user\n",
        "user_predictions = [pred for pred in predictions if pred.uid == specific_user_id]\n",
        "\n",
        "# Sort predictions by estimated rating in descending order\n",
        "user_predictions.sort(key=lambda x: x.est, reverse=True)\n",
        "\n",
        "# Function to calculate Precision@k\n",
        "def precision_at_k(predictions, k):\n",
        "    relevant_retrieved = sum([1 for _, _, true_r, est, _ in predictions[:k] if true_r >= 3.5 and est >= 3.5])\n",
        "    return relevant_retrieved / k if k > 0 else 0\n",
        "\n",
        "# Function to calculate Recall@k\n",
        "def recall_at_k(predictions, k):\n",
        "    relevant_retrieved = sum([1 for _, _, true_r, est, _ in predictions[:k] if true_r >= 3.5 and est >= 3.5])\n",
        "    relevant_items = sum([1 for _, _, true_r, _, _ in predictions if true_r >= 3.5])\n",
        "    return relevant_retrieved / relevant_items if relevant_items > 0 else 0\n",
        "\n",
        "# Function to calculate NDCG@k (Normalized Discounted Cumulative Gain)\n",
        "def ndcg_at_k(predictions, k):\n",
        "    # Calculate DCG (Discounted Cumulative Gain)\n",
        "    dcg = 0\n",
        "    for i, (_, _, true_r, est, _) in enumerate(predictions[:k]):\n",
        "        if true_r >= 3.5:  # Only consider relevant items (rating >= 3.5)\n",
        "            dcg += (2 ** true_r - 1) / np.log2(i + 2)  # i + 2 because log2 starts from 2\n",
        "\n",
        "    # Calculate IDCG (Ideal DCG) - best possible ranking\n",
        "    relevant_predictions = sorted([true_r for _, _, true_r, _, _ in predictions if true_r >= 3.5], reverse=True)\n",
        "    idcg = 0\n",
        "    for i, true_r in enumerate(relevant_predictions[:k]):\n",
        "        idcg += (2 ** true_r - 1) / np.log2(i + 2)\n",
        "\n",
        "    # Return NDCG (normalized DCG)\n",
        "    return dcg / idcg if idcg > 0 else 0\n",
        "\n",
        "# Define k for evaluation\n",
        "k = 10\n",
        "\n",
        "# Evaluate metrics for the specific user\n",
        "precision_k = precision_at_k(user_predictions, k)\n",
        "recall_k = recall_at_k(user_predictions, k)\n",
        "ndcg_k = ndcg_at_k(user_predictions, k)\n",
        "\n",
        "# Output the results\n",
        "print(f\"User ID: {specific_user_id}\")\n",
        "print(f\"Precision@{k}: {precision_k:.4f}\")\n",
        "print(f\"Recall@{k}: {recall_k:.4f}\")\n",
        "print(f\"NDCG@{k}: {ndcg_k:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
